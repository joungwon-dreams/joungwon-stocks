"""
Analyze all PDF reports in download/ directory
Extract common data elements and identify what's important
"""
import pdfplumber
import os
from collections import defaultdict
import re

def extract_all_text_from_pdf(pdf_path):
    """Extract all text from PDF"""
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        print(f"   âš ï¸ Error reading {pdf_path}: {e}")
    return text

def extract_data_elements(text):
    """Extract common data elements from report text"""
    elements = set()

    # Common financial indicators (Korean)
    patterns = [
        # Basic info
        r'(ì¢…ëª©ëª…|íšŒì‚¬ëª…|ê¸°ì—…ëª…)',
        r'(ì¢…ëª©ì½”ë“œ|í‹°ì»¤)',
        r'(í˜„ì¬ê°€|ëª©í‘œê°€|ëª©í‘œì£¼ê°€)',
        r'(íˆ¬ìì˜ê²¬|ì˜ê²¬)',

        # Price metrics
        r'(ì‹œê°€ì´ì•¡)',
        r'(52ì£¼\s*ìµœê³ ê°€|52ì£¼\s*ìµœì €ê°€)',
        r'(ìƒìŠ¹ì—¬ë ¥)',

        # Financial ratios
        r'(PER|P/E)',
        r'(PBR|P/B)',
        r'(ROE)',
        r'(EPS)',
        r'(BPS)',
        r'(ë°°ë‹¹ìˆ˜ìµë¥ )',

        # Growth metrics
        r'(ë§¤ì¶œì•¡|ì˜ì—…ì´ìµ|ìˆœì´ìµ)',
        r'(ë§¤ì¶œ\s*ì¦ê°€ìœ¨|ì˜ì—…ì´ìµ\s*ì¦ê°€ìœ¨)',
        r'(YoY|QoQ)',

        # Quarterly/Annual data
        r'(ë¶„ê¸°ë³„|ì—°ë„ë³„)',
        r'(1Q|2Q|3Q|4Q)',

        # Valuation
        r'(ì ì •ì£¼ê°€|Fair Value)',
        r'(Valuation)',
        r'(DCF|DDM)',

        # Market data
        r'(ì™¸êµ­ì¸\s*ì§€ë¶„ìœ¨|ì™¸êµ­ì¸\s*ë³´ìœ ë¹„ì¤‘)',
        r'(ê¸°ê´€\s*ìˆœë§¤ìˆ˜|ì™¸êµ­ì¸\s*ìˆœë§¤ìˆ˜)',
        r'(ê±°ë˜ëŸ‰|ê±°ë˜ëŒ€ê¸ˆ)',

        # Business segments
        r'(ì‚¬ì—…ë¶€ë¬¸|ë¶€ë¬¸ë³„)',
        r'(ì œí’ˆë³„|ì§€ì—­ë³„)',

        # Forecasts
        r'(ì „ë§|Outlook)',
        r'(ì¶”ì •ì¹˜|ì»¨ì„¼ì„œìŠ¤)',

        # Risk factors
        r'(ë¦¬ìŠ¤í¬|ìœ„í—˜)',
        r'(ëª¨ë©˜í…€)',

        # News/Events
        r'(ì´ìŠˆ|ì´ë²¤íŠ¸)',
        r'(ì‹¤ì ë°œí‘œ|ì–´ë‹)',

        # Peer comparison
        r'(ë™ì¢…ì—…ê³„|ê²½ìŸì‚¬)',
        r'(ì—…ì¢…|ì„¹í„°)',

        # Chart/Technical
        r'(ì°¨íŠ¸|ê¸°ìˆ ì )',
        r'(ì´ë™í‰ê· |ë³¼ë¦°ì €)',
    ]

    for pattern in patterns:
        if re.search(pattern, text, re.IGNORECASE):
            # Extract the matched keyword
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                elements.add(match.group(1))

    return elements

def analyze_all_reports():
    """Analyze all PDF files in download directory"""
    download_dir = "/Users/wonny/Dev/joungwon.stocks/download"
    pdf_files = [f for f in os.listdir(download_dir) if f.endswith('.pdf')]

    print(f"ğŸ” Analyzing {len(pdf_files)} PDF files...\n")

    # Track elements across all files
    element_frequency = defaultdict(int)
    all_elements = set()
    file_elements = {}

    for pdf_file in pdf_files:
        pdf_path = os.path.join(download_dir, pdf_file)
        print(f"ğŸ“„ Processing: {pdf_file}")

        # Extract text
        text = extract_all_text_from_pdf(pdf_path)

        # Extract elements
        elements = extract_data_elements(text)
        file_elements[pdf_file] = elements

        # Update frequency
        for elem in elements:
            element_frequency[elem] += 1
            all_elements.add(elem)

        print(f"   Found {len(elements)} elements\n")

    # Sort by frequency (importance indicator)
    sorted_elements = sorted(element_frequency.items(), key=lambda x: x[1], reverse=True)

    print("\n" + "="*80)
    print("ğŸ“Š ANALYSIS RESULTS")
    print("="*80)

    print(f"\nğŸ“ˆ Total unique elements found: {len(all_elements)}")
    print(f"ğŸ“ Total files analyzed: {len(pdf_files)}")

    print("\n\nğŸ¯ DATA ELEMENTS BY IMPORTANCE (Frequency in reports)")
    print("-"*80)
    print(f"{'Element':<30} {'Frequency':<15} {'Coverage':<15}")
    print("-"*80)

    for elem, freq in sorted_elements:
        coverage = f"{freq}/{len(pdf_files)} files"
        importance = "â­â­â­" if freq >= len(pdf_files) * 0.7 else "â­â­" if freq >= len(pdf_files) * 0.4 else "â­"
        print(f"{elem:<30} {freq:<15} {coverage:<15} {importance}")

    return sorted_elements, file_elements

if __name__ == "__main__":
    analyze_all_reports()
